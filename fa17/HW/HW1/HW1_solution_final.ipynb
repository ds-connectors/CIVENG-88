{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1. Basic probability and statistics\n",
    "\n",
    "The joint probability of variables $x$ and $y$ is modeled by:\n",
    "\n",
    "$\n",
    "    p(x,y)=\\left\\{\n",
    "                \\begin{array}{ll}\n",
    "                  72(xy^2-xy^3-x^2y^2+x^2y^3) \\hspace{1cm}  x,y \\in [0,1]\\\\\n",
    "                  0  \\hspace{5.8cm} \\text{otherwise}\n",
    "                \\end{array}\n",
    "              \\right.\n",
    "  $\n",
    "  \n",
    "Are $x$ and $y$ independent? If yes, please answer with number 1, else answer with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$p(x,y) = 72(xy^2 -xY^3 -x^2y^2 + x^2y^3) = 72xy^2(1-y-x+xy) = 72xy^2[1-y-x(1-y)] = 72x(1-x)y^2(1-y)$\n",
    "\n",
    "We have shown that $p(x,y) = f(x) \\times f(y)$, hence $x$ and $y$ are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q1 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Joint and marginal probabilities\n",
    "\n",
    "$X$ defines the maximum seismic intensity experienced by a site in the next 10 years, and it may assume 4 values: $X_1 = $ 'low', $X_2 = $ 'medium', $X_3 = $ 'high', and $X_4 = $ 'very high'.\n",
    "\n",
    "$Y$ defines the seismic damage on the building in that site, and it may assume 5 values: $Y_1 = $ 'no damage', $Y_2 = $ 'mild damage', $Y_3 = $ 'medium damage', $Y_4 = $ 'severe damage', and $Y_5 = $ 'collapse'.\n",
    "\n",
    "Marginal probability of $X$ and conditional probability of $Y$ given $X$ are modeled as:\n",
    "\n",
    "<img src=\"hw1_1.png\", width=\"500\">\n",
    "\n",
    "**2.1.** For each damage state, calculate the marginal probability of damage $p(Y)$.\n",
    "\n",
    "**hint: this is a column vector of length 5; note: Multiply the answer by 100 (percentage) and give the answer up to one decimal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "For each $Y$, $P(Y) = P(Y \\mid X_1) P(X_1) + P(Y \\mid X_2) P(X_2)+...$, We are given the table of $P(Y \\mid X)$, and a vector for $P(X)$, notice we want to take the linear combinations of the rows so we can make a matrix with the values of the table,  transpose it (we want to combine the rows not columns), and multiply it by the vector $x$.\n",
    "\n",
    "Good reference for how to multiply matrices : https://www.khanacademy.org/math/precalculus/precalc-matrices/multiplying-matrices-by-matrices/a/multiplying-matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Answer here:\n",
    "import numpy as np\n",
    "p_y_given_x = np.matrix([[0.7,0.3,0,0,0],[0.5,0.4,0.1,0,0],[0.3,0.3,0.35,0.04,0.01],[0,0.2,0.6,0.15,0.05]])\n",
    "p_x = np.matrix([[0.05],[0.25],[0.4],[0.3]])\n",
    "c = p_y_given_x.T * p_x\n",
    "d = c *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 28. ,  29.5,  34.5,   6.1,   1.9]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = c.T * 100\n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2.2.** For each damage state, calculate the conditional probability of damage given $X = X_2$\n",
    "\n",
    "**note: we are calculating $p(Y \\mid X = X_2)$; Multiply the answer by 100 (percentage) and give the answer up to one decimal (to round to 1 decimal use numpy.round('your vector', 1)).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** We are given the data for $P(Y \\mid X)$. We want to extract the row that corresponds to $P(Y \\mid X_2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 50.,  40.,  10.,   0.,   0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here:\n",
    "\n",
    "q3 = p_y_given_x[1,:] * 100 #The first argument is which row we want (remember we index at 0 so X_2 is at position 1). The second argument is for which column, the \":\" means all. \n",
    "q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.** For each damage state, calculate the joint probability of having that damage state and $X = X_2$\n",
    "\n",
    "**note: we are calculating $p(X_2 , Y)$; Multiply the answer by 100 (percentage) and give the answer up to one decimal. (to round to 1 decimal use numpy.round('your vector', 1))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** $P(X_2, Y) = P(X_2) P(X_2 \\mid Y)$. One method to calculate this is using np.multiply, which multiplies the values of the $X$ vector with the corresponding row of the $P(Y \\mid X)$ matrix. Our answer will be the row for $X_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 12.5,  10. ,   2.5,   0. ,   0. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_xy = np.multiply(p_y_given_x , p_x)\n",
    "p_xy[1, : ] * 100 #Remember we index at 0, so the row for X_2 is at row 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 12.5,  10. ,   2.5,   0. ,   0. ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here:\n",
    "q4 = p_xy[1,] * 100\n",
    "q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.** For each seismic intensity, calculate the conditional probability of that intensity given $Y = Y_3$\n",
    "\n",
    "**note: we are calculating $p(X \\mid Y = Y_3)$; Multiply the answer by 100 (percentage) and give the answer up to one decimal. (to round to 1 decimal use numpy.round('your vector', 1))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** The conditional probability is represented by $P(X \\mid Y)$. Recall that $P(X \\mid Y) = \\frac{P(X,Y)}{P(Y)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_y = np.sum(p_xy,0) #Returns the sum of each column, which gives us P(Y)\n",
    "p_x_given_y = p_xy / p_y #Returns a matrix with P(X|Y) in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ],\n",
       "       [  7.2],\n",
       "       [ 40.6],\n",
       "       [ 52.2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We want Y=Y_3, so we want the third column.\"\"\"\n",
    "# Answer here:\n",
    "\n",
    "q5 = np.round(p_x_given_y[:,2]*100,1)\n",
    "q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Contuning on probability\n",
    "\n",
    "On day zero, the number of trucks in a parking lot is $X_0$. Assume $X_0 = 1$ with probability 20%, $X_0 = 2$ with probability 50% and $X_0 = 3$, with probability 30%. Between day zero and day one, assume one truck can leave (with probability 25%), one truck can be added (with probability 25%), or the number of trucks can stay the same (with probability 50%). $X_1$ is the number of trucks on day one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1.** What is the probability that $X_1 = 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "$p(X_1 = 1) = p(X_0 = 1) p(\\Delta X = 0) + p(X_0 = 2) p(\\Delta X = -1) + p(X_0 = 2) p(\\Delta X = -2)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q6 = 22.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2.** What is the probability that $X_1 = 5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** same as above 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q7 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3.** What is the probability that $X_1 > X_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** $p(\\Delta X > 0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q8 = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4.** If there are 3 trucks at day one, what is the conditional probability that there were 2 trucks at day zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "\n",
    "$p(X_0 = 2 \\mid X_1 = 3) = \\frac{p(X_0 = 2, X_1 = 3)}{p(X_1 = 3)}$\n",
    "\n",
    "$p(X_0 = 2, X_1 = 3) = p(X_1 = 3 \\mid X_0 = 2) p(X_0 = 2)$ and $p(X_1 = 3)$ can be calculated as in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer here:\n",
    "\n",
    "q9 = 45.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Census Data\n",
    "\n",
    "In this question load the census data (bay_area_census_age.csv) and implement your method to answer following questions:\n",
    "\n",
    "**4.1.** identify census tracts with predominantly young population (we can define the predominantly young population as if the portion of population under 29 years old is more than 80% of the total population). Your output should be a list of census tract ids (this is the 'NAME' field in the data table).\n",
    "\n",
    "**note: Once you find those tracts just enter the numbers below, for example if you find two tracts ('Census Tract 21', 'Census Tract 434'), your answer would be [21,434]**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "The idea behind this problem is taking the sum across each row to determine the total population\n",
    "under 29 for the respective correct columns. To do this, first filter the table to only include the columns\n",
    "of age groups that are under 29, then use the .apply method to sum the contents of each row to find the total \n",
    "population in that demographic. After that you divide the number by the total population and determine which \n",
    "of the states have higher than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>NAME</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 4226   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 4227   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 4228   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 332.01 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 5009.02</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 5116.08</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Census Tract 5130   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "NAME\n",
       "Census Tract 4226\n",
       "Census Tract 4227\n",
       "Census Tract 4228\n",
       "Census Tract 332.01\n",
       "Census Tract 5009.02\n",
       "Census Tract 5116.08\n",
       "Census Tract 5130"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datascience import *\n",
    "\n",
    "data = Table.read_table(\"bay_area_census_age.csv\")\n",
    "\n",
    "un29 = data.select(['Under 5 years', '5 to 9 years', '10 to 14 years',\n",
    "                    '15 to 19 years', '20 to 24 years', '25 to 29 years'])\n",
    "popsum = un29.apply(sum)\n",
    "data['young population'] = popsum\n",
    "data['young perc'] = data['young population'] / data['Total Population'] * 100\n",
    "ff = data.where(data['young perc'] >= 80).select(['NAME'])\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer here:\n",
    "\n",
    "q10 = [4226,4227,4228,332.01,5009.02,5116.08,5130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Find the three closest tracts to Paris Baguette in Downtown Berkeley (latitude = 37.869941, longitude = -122.268377), and report the mean and standard deviation of total population in those tracts. \n",
    "\n",
    "**note: the function to find the distance of tracts to the specific lat/long is provided below. Please round your answers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_on_sphere(lat1, long1, lat2, long2):\n",
    "\n",
    "    # Convert latitude and longitude to spherical coordinates in radians.\n",
    "    degrees_to_radians = np.pi/180.0\n",
    "        \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "        \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "        \n",
    "    # We can compute spherical distance from spherical coordinates.\n",
    "    cos = (np.sin(phi1)*np.sin(phi2)*np.cos(theta1-theta2)+\n",
    "           np.cos(phi1)*np.cos(phi2))\n",
    "    arc = np.arccos( cos )\n",
    "\n",
    "    # Multiply arc by the radius of the earth to get length.\n",
    "    return 3960.*arc #to get distance in miles\n",
    "\n",
    "def rotate_table(table):\n",
    "    '''transforms a 2 x n table to be an n x 2 table'''\n",
    "    return Table().with_columns(['Columns', list(table.labels),\n",
    "                                 'Values', list(table.to_array()[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Apply the distance_on_sphere function with the latitude and longitude of Paris Baguette as the first input and the values from columns 'INTPTLAT10' and 'INTPTLON10' as the second and third. Add this new column to the original table and sort the data from least to most and take the first 3. From there we can use built in numpy\n",
    "functions to calculate the mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/datascience/tables.py:362: FutureWarning: column lists are deprecated; pass each as an argument\n",
      "  \"column lists are deprecated; pass each as an argument\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1935.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat1, lon1 = 37.869941, -122.268377\n",
    "data['distance to Paris'] = data.apply(lambda lat2, lon2 : distance_on_sphere(lat1, lon1, lat2, lon2), \n",
    "                                          ['INTPTLAT10', 'INTPTLON10'])\n",
    "\n",
    "\n",
    "c = data.sort('distance to Paris')\n",
    "d = c['Total Population'][0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Enter mean here:\n",
    "\n",
    "q11 = round(np.mean(d),0)\n",
    "\n",
    "# Enter standard deviation here:\n",
    "\n",
    "q12 = round(np.std(d),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Traffic count on Bay Bridge\n",
    "\n",
    "In this question load the traffic data on bay bridge (pems_output.csv.csv) and implement your method for: \n",
    "\n",
    "\n",
    "**5.1** identifying the best (most Flow) lane to travel on for the following period of time: \n",
    "between 8pm to 11pm\n",
    "\n",
    "**note: the functions to get the hours (as we had in Lab 1) is given below** \n",
    "\n",
    "**If your answer is Lane 1, enter just number 1, and 2 or 3 or 4 for other lanes respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Note that 'Hour' column is a time stamp, so you can use the pandas function .to_datetime to calculate the hours of the day. We filter the data to only include times between 8pm (20) and 11pm (23). Next we filter the  data to only include the flow of each lane. Then we take the sum of each column using np.sum and choose the the lane with the highest Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Hour</th> <th>Lane 1 Flow (Veh/Hour)</th> <th>Lane 2 Flow (Veh/Hour)</th> <th>Lane 3 Flow (Veh/Hour)</th> <th>Lane 4 Flow (Veh/Hour)</th> <th>Lane 5 Flow (Veh/Hour)</th> <th>Flow (Veh/Hour)</th> <th># Lane Points</th> <th>% Observed</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 0:00</td> <td>34                    </td> <td>347                   </td> <td>372                   </td> <td>291                   </td> <td>119                   </td> <td>1163           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 1:00</td> <td>20                    </td> <td>199                   </td> <td>295                   </td> <td>230                   </td> <td>74                    </td> <td>818            </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 2:00</td> <td>17                    </td> <td>248                   </td> <td>342                   </td> <td>267                   </td> <td>114                   </td> <td>988            </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 3:00</td> <td>158                   </td> <td>427                   </td> <td>433                   </td> <td>347                   </td> <td>164                   </td> <td>1529           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 4:00</td> <td>883                   </td> <td>1033                  </td> <td>912                   </td> <td>737                   </td> <td>543                   </td> <td>4108           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 5:00</td> <td>2037                  </td> <td>1944                  </td> <td>1734                  </td> <td>1617                  </td> <td>1594                  </td> <td>8926           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 6:00</td> <td>1838                  </td> <td>1844                  </td> <td>1709                  </td> <td>1715                  </td> <td>1626                  </td> <td>8732           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 7:00</td> <td>1790                  </td> <td>1883                  </td> <td>1760                  </td> <td>1720                  </td> <td>1627                  </td> <td>8780           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 8:00</td> <td>1739                  </td> <td>1820                  </td> <td>1686                  </td> <td>1621                  </td> <td>1617                  </td> <td>8483           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>1/14/2016 9:00</td> <td>1709                  </td> <td>1705                  </td> <td>1681                  </td> <td>1591                  </td> <td>1631                  </td> <td>8317           </td> <td>60           </td> <td>100       </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (160 rows omitted)</p"
      ],
      "text/plain": [
       "Hour           | Lane 1 Flow (Veh/Hour) | Lane 2 Flow (Veh/Hour) | Lane 3 Flow (Veh/Hour) | Lane 4 Flow (Veh/Hour) | Lane 5 Flow (Veh/Hour) | Flow (Veh/Hour) | # Lane Points | % Observed\n",
       "1/14/2016 0:00 | 34                     | 347                    | 372                    | 291                    | 119                    | 1163            | 60            | 100\n",
       "1/14/2016 1:00 | 20                     | 199                    | 295                    | 230                    | 74                     | 818             | 60            | 100\n",
       "1/14/2016 2:00 | 17                     | 248                    | 342                    | 267                    | 114                    | 988             | 60            | 100\n",
       "1/14/2016 3:00 | 158                    | 427                    | 433                    | 347                    | 164                    | 1529            | 60            | 100\n",
       "1/14/2016 4:00 | 883                    | 1033                   | 912                    | 737                    | 543                    | 4108            | 60            | 100\n",
       "1/14/2016 5:00 | 2037                   | 1944                   | 1734                   | 1617                   | 1594                   | 8926            | 60            | 100\n",
       "1/14/2016 6:00 | 1838                   | 1844                   | 1709                   | 1715                   | 1626                   | 8732            | 60            | 100\n",
       "1/14/2016 7:00 | 1790                   | 1883                   | 1760                   | 1720                   | 1627                   | 8780            | 60            | 100\n",
       "1/14/2016 8:00 | 1739                   | 1820                   | 1686                   | 1621                   | 1617                   | 8483            | 60            | 100\n",
       "1/14/2016 9:00 | 1709                   | 1705                   | 1681                   | 1591                   | 1631                   | 8317            | 60            | 100\n",
       "... (160 rows omitted)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Table.read_table('pems_output.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/datascience/tables.py:192: FutureWarning: Implicit column method lookup is deprecated.\n",
      "  warnings.warn(\"Implicit column method lookup is deprecated.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Lane 1 Flow (Veh/Hour)</th> <th>Lane 2 Flow (Veh/Hour)</th> <th>Lane 3 Flow (Veh/Hour)</th> <th>Lane 4 Flow (Veh/Hour)</th> <th>Lane 5 Flow (Veh/Hour)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>21698                 </td> <td>28251                 </td> <td>25420                 </td> <td>21102                 </td> <td>11924                 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Lane 1 Flow (Veh/Hour) | Lane 2 Flow (Veh/Hour) | Lane 3 Flow (Veh/Hour) | Lane 4 Flow (Veh/Hour) | Lane 5 Flow (Veh/Hour)\n",
       "21698                  | 28251                  | 25420                  | 21102                  | 11924"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plots\n",
    "%matplotlib inline\n",
    "data['Hour day'] = pd.to_datetime(data['Hour']).hour\n",
    "c = data.where((data['Hour day'] >= 20) & (data['Hour day'] <= 23))\n",
    "d = c.select(['Lane 1 Flow (Veh/Hour)', 'Lane 2 Flow (Veh/Hour)', 'Lane 3 Flow (Veh/Hour)', 'Lane 4 Flow (Veh/Hour)','Lane 5 Flow (Veh/Hour)'])\n",
    "f = Table.to_array(d)\n",
    "f = f.tolist()\n",
    "ff = np.sum(f,0)\n",
    "np.max(ff)\n",
    "np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your final answer here:\n",
    "\n",
    "q13 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2.** identifying the worst (least flow) lane to travel on for the following period of time: \n",
    "between 8pm to 11pm between 5pm to 8pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Replicate the work from 5.1 but instead for 5pm (17) and 8pm (20) and pick the lowest flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/datascience/tables.py:192: FutureWarning: Implicit column method lookup is deprecated.\n",
      "  warnings.warn(\"Implicit column method lookup is deprecated.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Lane 1 Flow (Veh/Hour)</th> <th>Lane 2 Flow (Veh/Hour)</th> <th>Lane 3 Flow (Veh/Hour)</th> <th>Lane 4 Flow (Veh/Hour)</th> <th>Lane 5 Flow (Veh/Hour)</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>33020                 </td> <td>38159                 </td> <td>35711                 </td> <td>32095                 </td> <td>26025                 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Lane 1 Flow (Veh/Hour) | Lane 2 Flow (Veh/Hour) | Lane 3 Flow (Veh/Hour) | Lane 4 Flow (Veh/Hour) | Lane 5 Flow (Veh/Hour)\n",
       "33020                  | 38159                  | 35711                  | 32095                  | 26025"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = data.where((data['Hour day'] >= 17) & (data['Hour day'] <= 20))\n",
    "d = c.select(['Lane 1 Flow (Veh/Hour)', 'Lane 2 Flow (Veh/Hour)', 'Lane 3 Flow (Veh/Hour)', 'Lane 4 Flow (Veh/Hour)','Lane 5 Flow (Veh/Hour)'])\n",
    "np.sum(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your final answer here:\n",
    "\n",
    "q14 = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. TAZ data\n",
    "\n",
    "In this question you will play with some data from the Metropolitan Transportation Commission on travel time from one Traffic Analysis Zone (TAZ) to another. \n",
    "\n",
    "##### The Dataset\n",
    "\n",
    "##### MTC travel skims\n",
    "\n",
    "The Metropolitan Transportation Commission (MTC) is the regional transportation planning organization for the Bay Area. They host a database with average travel time, cost, and distance from each traffic analysis zone (TAZ) to all other TAZs in the Bay Area. The files have data for driving alone, carpooling, walking to transit, driving to transit, walking, and biking. \n",
    "\n",
    "We have pre-processed the data from the morning commute to include only TAZs around San Francisco, Oakland and Berkeley. The file with inter-TAZ travel time is sf_oak_traveltimes_bymode.csv.\n",
    "\n",
    "More info on the dataset can be found here - http://analytics.mtc.ca.gov/foswiki/Main/SimpleSkims. \n",
    "The descriptions of the columns in the data set are shown below:\n",
    "\n",
    "|column|description|\n",
    "|---|---|\n",
    "|origin|Origin transportation analysis zone|\n",
    "|destination|Destination transportation analysis zone|\n",
    "|drive alone|Door-to-door time for the drive alone travel mode (i.e. single occupant private automobile)|\n",
    "|shared ride (2 people)|Door-to-door time for the shared ride 2 travel mode (i.e. double occupant private automobile)|\n",
    "|shared ride (3 people)|Door-to-door time for the shared ride 3+ travel mode (i.e. three-or-more occupants traveling in a private vehicle)|\n",
    "|walk|Door-to-door time for walking|\n",
    "|bike|Door-to-door time for bicycling|\n",
    "|walk-transit-walk|Door-to-door time for walk to transit to walk paths|\n",
    "|drive-transit-walk|Door-to-door time for drive to transit to walk paths|\n",
    "| walk-transit-drive|Door-to-door time for walk to transit to drive paths (returning home on a park-and-ride tour)|\n",
    "\n",
    "\n",
    "(The raw data with all Bay Area TAZs can be found at https://mtcdrive.app.box.com/2015-03-116)\n",
    "\n",
    "\n",
    "**6.1:** what is the drive alone travel time from origin TAZ 10 (in downtown SF) to destination TAZ \n",
    "1019 (the TAZ at UC Berkeley) according to this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** First filter the data to only include rows that have 10 as the origin, then filter the data to only include data where the destination is 1019. This should result in a table with one row, where the 'drive alone' number is our desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23.64])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_data = Table.read_table(\"sf_oak_traveltimes_bymode.csv\")\n",
    "travel_data.where('origin',10).where('destination', 1019)['drive alone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Answer here:\n",
    "\n",
    "q15 = 23.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2:** what is the worst mode of travel (most travel time) for the above mentioned origin-destination according to the data? \n",
    "\n",
    "**note: if you get the travel time of -999, that means that mode is not available, simply disregard those**\n",
    "\n",
    "**Please just enter the name of the travel model as a string below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** First filter the data to only include rows with 10 as the origin and 1019 as its destination. This should give you a single row, which you can manually check which category has the worst mode of travel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>origin</th> <th>destination</th> <th>drive alone</th> <th>shared ride (2 people)</th> <th>shared ride (3 people)</th> <th>walk</th> <th>bike</th> <th>walk-transit-walk</th> <th>drive-transit-walk</th> <th>walk-transit-drive</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>1019       </td> <td>23.64      </td> <td>23.64                 </td> <td>23.64                 </td> <td>-999</td> <td>-999</td> <td>51.05            </td> <td>48.76             </td> <td>44.04             </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "origin | destination | drive alone | shared ride (2 people) | shared ride (3 people) | walk | bike | walk-transit-walk | drive-transit-walk | walk-transit-drive\n",
       "10     | 1019        | 23.64       | 23.64                  | 23.64                  | -999 | -999 | 51.05             | 48.76              | 44.04"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel_data.where('origin',10).where('destination', 1019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your final answer here:\n",
    "\n",
    "q16 = 'walk-transit-walk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3** Among the first 100 destinations, which one is the closet to origin 10 only consideting the travel model, biking\n",
    "\n",
    "**note: exclude those destinations where biking is not available (travel time is -999)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** For this question, filter the data to only include the first 100 destinations, starting at origin 10, where the bike data is not -999 and sort is in ascending order. Choose the top option that is not 10 itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>origin</th> <th>destination</th> <th>bike</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>10         </td> <td>1.05</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>20         </td> <td>2.1 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>9          </td> <td>2.45</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>11         </td> <td>2.45</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>79         </td> <td>3.55</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>76         </td> <td>3.7 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>8          </td> <td>3.9 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>30         </td> <td>4.3 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>19         </td> <td>4.35</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>10    </td> <td>21         </td> <td>4.55</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (89 rows omitted)</p"
      ],
      "text/plain": [
       "origin | destination | bike\n",
       "10     | 10          | 1.05\n",
       "10     | 20          | 2.1\n",
       "10     | 9           | 2.45\n",
       "10     | 11          | 2.45\n",
       "10     | 79          | 3.55\n",
       "10     | 76          | 3.7\n",
       "10     | 8           | 3.9\n",
       "10     | 30          | 4.3\n",
       "10     | 19          | 4.35\n",
       "10     | 21          | 4.55\n",
       "... (89 rows omitted)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(travel_data\n",
    ".where('destination', are.below_or_equal_to(100)) #First 100 destinations\n",
    ".where('origin', 10) #Starting at origin 10\n",
    ".where('bike', are.not_equal_to(-999)) #Only available data\n",
    ".select('origin', 'destination', 'bike') #Only interested in where is starts, ends, and bike distance\n",
    ".sort('bike') #Sort the data from closest to furthest \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your final answer here:\n",
    "\n",
    "q17 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus question\n",
    "\n",
    "###### Conditional independence\n",
    "\n",
    "The notation $X \\perp Y$ indicates that random variables $X$ and $Y$ are independent. Similarly, $X \\perp Y \\mid Z$ means that $X$ and $Y$ are conditionally independent given $Z$, that is $p(x \\perp y \\mid z) = p(x \\mid z)p(y \\mid z)$.\n",
    "\n",
    "Is the following statements about conditional independence true or false? **If it is true answer with number 1, if false answer with number 0.**\n",
    "\n",
    "- $(X \\perp (Y,W) \\mid Z)$ implies $X \\perp Y \\mid Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "$(X \\perp (Y,W) \\mid Z) \\rightarrow p(X,Y,W \\mid Z) = p(X \\mid Z) p(Y,W \\mid Z)$\n",
    "\n",
    "Now we sum over $W$ on both sides:\n",
    "\n",
    "$\\sum_W p(X,Y,W \\mid Z) = \\sum_W p(X \\mid Z) p(Y,W \\mid Z)$\n",
    "\n",
    "$\\sum_W p(X,Y,W \\mid Z) = p(X \\mid Z) \\sum_W  p(Y,W \\mid Z)$\n",
    "\n",
    "$p(X,Y \\mid Z) = p(X \\mid Z) p(Y\\mid Z) \\rightarrow X \\perp Y \\mid Z$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q18 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $(X \\perp Y \\mid Z)$ and $((X,Y) \\perp W \\mid Z)$ implies $X \\perp W \\mid Z$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "$(X \\perp Y \\mid Z) \\rightarrow p(X,Y \\mid Z) = p(X \\mid Z) p(Y \\mid Z)$\n",
    "\n",
    "$((X,Y) \\perp W \\mid Z) \\rightarrow p(X,Y,W \\mid Z) = p(X,Y \\mid Z) p(W \\mid Z)$\n",
    "\n",
    "$p(X,Y,W \\mid Z) = p(X \\mid Z) p(Y \\mid Z) p(W \\mid Z)$\n",
    "\n",
    "$\\sum_Y p(X,Y,W \\mid Z) = \\sum_Y p(X \\mid Z)  p(Y \\mid Z) p(W \\mid Z)$\n",
    "\n",
    "$\\sum_Y p(X,Y,W \\mid Z) =  p(X \\mid Z)  \\sum_Y p(Y \\mid Z) p(W \\mid Z)$\n",
    "\n",
    "$p(X,W \\mid Z) =  p(X \\mid Z) p(W \\mid Z) \\rightarrow X \\perp W \\mid Z$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q19 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $(X \\perp (Y,W) \\mid Z)$ and $(Y \\perp W \\mid Z)$ implies $(X,W) \\perp Y \\mid Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** \n",
    "\n",
    "from $(X \\perp (Y,W) \\mid Z)$ and $(Y \\perp W \\mid Z)$ we can easily conclude that $(X \\perp W \\mid Z)$. \n",
    "\n",
    "So, $p(X,Y,W \\mid Z) = p(X \\mid Z) p(Y,W \\mid Z) = p(X \\mid Z) p(Y \\mid Z) p(W \\mid Z)$\n",
    "\n",
    "$p(X,Y,W \\mid Z) = p(X,W \\mid Z) p(Y \\mid Z) \\rightarrow (X,W) \\perp Y \\mid Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here:\n",
    "\n",
    "q20 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load OKpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('HW1.ok')\n",
    "_ = ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to OKpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
